# BackPropagation
Implementing a basic version of the backpropagation learning algorithm for a neural network of 2 inputs, 2 hidden, and 1 output unit. Taught a network to mimic simple logical functions such as AND and XOR. Conducted several experiments to evaluate the effects of momentum and learning rate
